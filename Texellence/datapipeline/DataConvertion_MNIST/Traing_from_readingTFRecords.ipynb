{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IMAGE_PIXELS', 'IMAGE_SIZE', 'NUM_CLASSES', '__builtins__', '__doc__', '__file__', '__name__', '__package__', 'absolute_import', 'division', 'evaluation', 'inference', 'loss', 'math', 'print_function', 'tf', 'training']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Converts MNIST data to TFRecords file format with Example protos.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import mnist\n",
    "# mnist is a prewriten py file containing the definition of the graph\n",
    "print(dir(mnist))\n",
    "\n",
    "TRANFILE = 'data/train.tfrecords'\n",
    "TESTFILE = 'data/test.tfrecords'\n",
    "VALIDATIONFILe=  'data/validation.tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_and_decode(filename_queue):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(\n",
    "      serialized_example,\n",
    "      # Defaults are not specified since both keys are required.\n",
    "      features={\n",
    "          'label': tf.FixedLenFeature([], tf.int64),\n",
    "          'image_raw': tf.FixedLenFeature([], tf.string)\n",
    "            \n",
    "      })\n",
    "\n",
    "    # Convert from a scalar string tensor (whose single string has\n",
    "    # length mnist.IMAGE_PIXELS) to a uint8 tensor with shape\n",
    "    # [mnist.IMAGE_PIXELS].\n",
    "    image = tf.decode_raw(features['image_raw'], tf.float32)\n",
    "    image.set_shape([mnist.IMAGE_PIXELS])\n",
    "\n",
    "    # OPTIONAL: Could reshape into a 28x28 image and apply distortions\n",
    "    # here.  Since we are not applying any distortions in this\n",
    "    # example, and the next step expects the image to be flattened\n",
    "    # into a vector, we don't bother.\n",
    "\n",
    "    # Convert from [0, 255] -> [-0.5, 0.5] floats.\n",
    "    image = image - 0.5\n",
    "\n",
    "    # Convert label from a scalar uint8 tensor to an int32 scalar.\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def inputs(filename, batch_size, num_epochs):\n",
    "    \"\"\"Reads input data num_epochs times.\n",
    "    Args:\n",
    "      filename: filename of TFRecords\n",
    "      batch_size: Number of examples per returned batch.\n",
    "      num_epochs: Number of times to read the input data, or 0/None to\n",
    "      train forever.\n",
    "    Returns:\n",
    "        A tuple (images, labels), where:\n",
    "        * images is a float tensor with shape [batch_size, mnist.IMAGE_PIXELS]\n",
    "        in the range [-0.5, 0.5].\n",
    "        * labels is an int32 tensor with shape [batch_size] with the true label,\n",
    "        a number in the range [0, mnist.NUM_CLASSES).\n",
    "    Note that an tf.train.QueueRunner is added to the graph, which\n",
    "    must be run using e.g. tf.train.start_queue_runners().\n",
    "    \"\"\"\n",
    "    if not num_epochs: num_epochs = None\n",
    "     \n",
    "\n",
    "    with tf.name_scope('input'):\n",
    "        filename_queue = tf.train.string_input_producer(\n",
    "            [filename], num_epochs=num_epochs)\n",
    "\n",
    "        # Even when reading in multiple threads, share the filename\n",
    "        # queue.\n",
    "        image, label = read_and_decode(filename_queue)\n",
    "\n",
    "        # Shuffle the examples and collect them into batch_size batches.\n",
    "        # (Internally uses a RandomShuffleQueue.)\n",
    "        # We run this in two threads to avoid being a bottleneck.\n",
    "        images, sparse_labels = tf.train.shuffle_batch(\n",
    "            [image, label], batch_size=batch_size, num_threads=2,\n",
    "            capacity=1000 + 3 * batch_size,\n",
    "            # Ensures a minimum amount of shuffling of examples.\n",
    "            min_after_dequeue=1000)\n",
    "\n",
    "    return images, sparse_labels\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train MNIST for a number of steps and save the session to model/.\n",
    "\n",
    "# Tell TensorFlow that the model will be built into the default Graph.\n",
    "with tf.Graph().as_default(): # define graph\n",
    "    # Input images and labels from the training set\n",
    "    images, labels = inputs('data/train.tfrecords', batch_size=100,\n",
    "                                num_epochs=20)\n",
    "\n",
    "    # Build a Graph that computes predictions from the inference model.\n",
    "    logits = mnist.inference(images,\n",
    "                                 128,# number of neurons at hiddenlayer 1\n",
    "                                 32) # number of neurons at hiddenlayer 2\n",
    "\n",
    "    # Add to the Graph the loss calculation.\n",
    "    loss = mnist.loss(logits, labels)\n",
    "\n",
    "    # Add to the Graph operations that train the model.\n",
    "    train_op = mnist.training(loss, learning_rate=0.01)\n",
    "\n",
    "    # The op for initializing the variables.\n",
    "    init_op = tf.group(tf.initialize_all_variables(),\n",
    "                        tf.initialize_local_variables())\n",
    "    # Add ops to save and restore all the variables.\n",
    "    saver = tf.train.Saver()\n",
    "    # Create a session for running operations in the Graph.\n",
    "    sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=4))\n",
    "    # by default, tf.Session has 2 threads, \n",
    "    # you can use config=tf.ConfigProto(intra_op_parallelism_threads=NUM_THREADS) \n",
    "    # to specify the number of threads\n",
    "\n",
    "    # Initialize the variables (the trained variables and the \n",
    "    # epoch counter).\n",
    "    sess.run(init_op)\n",
    "\n",
    "    _, loss_value = sess.run([train_op, loss])\n",
    "     \n",
    "    duration = time.time() - start_time\n",
    "    save_path = saver.save(sess, 'model_parameter/mnist_128_32.cpkt')\n",
    "    sess.close()\n",
    "\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train MNIST for a number of steps and save the session to model/.\n",
    "\n",
    "# Tell TensorFlow that the model will be built into the default Graph.\n",
    "## the following code is to  use multi-threads\n",
    "with tf.Graph().as_default(): # define graph\n",
    "    # Input images and labels from the training set\n",
    "    images, labels = inputs('data/train.tfrecords', batch_size=100,\n",
    "                                num_epochs=20)\n",
    "\n",
    "    ### Build a Graph that computes predictions from the inference model.\n",
    "    logits = mnist.inference(images,\n",
    "                                 128,# number of neurons at hiddenlayer 1\n",
    "                                 32) # number of neurons at hiddenlayer 2\n",
    "\n",
    "    ### Add to the Graph the loss calculation.\n",
    "    loss = mnist.loss(logits, labels)\n",
    "\n",
    "    ### Add to the Graph operations that train the model.\n",
    "    train_op = mnist.training(loss, learning_rate=0.01)\n",
    "\n",
    "    ### The op for initializing the variables.\n",
    "    init_op = tf.group(tf.initialize_all_variables(),\n",
    "                        tf.initialize_local_variables())\n",
    "    ### Add ops to save and restore all the variables.\n",
    "    saver = tf.train.Saver()\n",
    "    ### Create a session for running operations in the Graph.\n",
    "    sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=4))\n",
    "    ### by default, tf.Session has 2 threads, \n",
    "    ### you can use config=tf.ConfigProto(intra_op_parallelism_threads=NUM_THREADS) \n",
    "    ### to specify the number of threads\n",
    "\n",
    "    ### Initialize the variables (the trained variables and the \n",
    "    ### epoch counter).\n",
    "    sess.run(init_op)\n",
    "\n",
    "    ### Start input enqueue threads.\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    ####\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        step = 0\n",
    "        total_duration = 0\n",
    "        while not coord.should_stop():\n",
    "            \n",
    "\n",
    "            # Run one step of the model.  The return values are\n",
    "            # the activations from the `train_op` (which is\n",
    "            # discarded) and the `loss` op.  To inspect the values\n",
    "            # of your ops or variables, you may include them in\n",
    "            # the list passed to sess.run() and the value tensors\n",
    "            # will be returned in the tuple from the call.\n",
    "            _, loss_value = sess.run([train_op, loss])\n",
    "\n",
    "            \n",
    "            # total_duration+=duration\n",
    "\n",
    "            # Print an overview fairly often.\n",
    "            if step % 1000 == 0:\n",
    "                print('Step %d: loss = %.2f ' % (step, loss_value,))\n",
    "            step += 1\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done training for %d epochs, %d steps.' % (2, step))\n",
    "    finally:\n",
    "        # When done, ask the threads to stop.\n",
    "        coord.request_stop()\n",
    "\n",
    "        ### Wait for threads to finish.\n",
    "    coord.join(threads)\n",
    "    duration = time.time() - start_time\n",
    "    save_path = saver.save(sess, 'model_parameter/mnist_128_32.cpkt')\n",
    "    sess.close()\n",
    "\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168.582716942\n"
     ]
    }
   ],
   "source": [
    "print(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173.698046684\n"
     ]
    }
   ],
   "source": [
    "print(total_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build the graph and reload the train variables\n",
    "all the trainable variable is in the collection tf.trainable_variables(), we only load those varialbes to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: predict_right = 94.00 (0.128 sec)\n",
      "Step 10: predict_right = 92.00 (0.012 sec)\n",
      "Step 20: predict_right = 92.00 (0.012 sec)\n",
      "Step 30: predict_right = 96.00 (0.012 sec)\n",
      "Step 40: predict_right = 93.00 (0.013 sec)\n",
      "Step 50: predict_right = 95.00 (0.012 sec)\n",
      "Step 60: predict_right = 97.00 (0.013 sec)\n",
      "Step 70: predict_right = 91.00 (0.015 sec)\n",
      "Step 80: predict_right = 98.00 (0.013 sec)\n",
      "Step 90: predict_right = 97.00 (0.003 sec)\n",
      "Done training for 2 epochs, 100 steps.\n",
      "accuracy of the model on test is 0.94\n",
      "9401,10000\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(): \n",
    "    images, labels = inputs('data/test.tfrecords', batch_size=100,\n",
    "                                num_epochs=1)\n",
    "\n",
    "    \n",
    "    logits = mnist.inference(images,\n",
    "                                 128,# number of neurons at hiddenlayer 1\n",
    "                                 32) # number of neurons at hiddenlayer 2\n",
    "    correct = tf.nn.in_top_k(logits, labels, 1)\n",
    "    predict_right = tf.reduce_sum(tf.cast(correct, tf.int32))\n",
    "    \n",
    "    saver = tf.train.Saver(tf.trainable_variables())\n",
    "    init_op = tf.group(tf.initialize_all_variables(),\n",
    "                        tf.initialize_local_variables())\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        saver.restore(sess,'model_parameter/mnist_128_32.cpkt')\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    #\n",
    "\n",
    "        try:\n",
    "            step = 0\n",
    "            total_right = 0\n",
    "            total_example = 0\n",
    "            while not coord.should_stop():\n",
    "                start_time = time.time()\n",
    "\n",
    "                \n",
    "                right_case = predict_right.eval()\n",
    "                duration = time.time() - start_time\n",
    "\n",
    "                # Print an overview fairly often.\n",
    "                if step % 10 == 0:\n",
    "                    print('Step %d: predict_right = %.2f (%.3f sec)' % (step, right_case,\n",
    "                                                     duration))\n",
    "                \n",
    "                \n",
    "                step += 1\n",
    "                total_right += right_case\n",
    "                total_example += int(images.get_shape()[0])\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('Done training for %d epochs, %d steps.' % (2, step))\n",
    "        finally:\n",
    "            # When done, ask the threads to stop.\n",
    "            coord.request_stop()\n",
    "\n",
    "        # Wait for threads to finish.\n",
    "        coord.join(threads)\n",
    "        print('accuracy of the model on test is %.2f' %(total_right*1.0/total_example))  \n",
    "        print('%d,%d' %(total_right,total_example))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### however, it is not convenient to gather images when using TFRecords and multiple threads \n",
    "### due to the map-reduce principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Python2]",
   "language": "python",
   "name": "conda-env-Python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
